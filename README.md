# HyperSRCNN: Hypernetworks for Varying Scaling Factors in Image Super Resolution

This repository implements HyperSRCNN, a hypernetwork-based approach to single image super-resolution that leverages a single meta-network to handle multiple scale factors through parameter generation.

## üìö Overview

HyperSRCNN addresses a key limitation in traditional super-resolution models: the need to train separate models for different upscaling factors. Instead, HyperSRCNN uses a hypernetwork architecture that dynamically generates weights for a target SRCNN model conditioned on the desired scale factor, enabling a single model to handle multiple scaling operations efficiently.

![HyperSRCNN Architecture](https://via.placeholder.com/800x400?text=HyperSRCNN+Architecture)

## üîë Key Features

- **Multi-scale capability**: A single model handles multiple scale factors (2√ó, 4√ó, 8√ó, 16√ó)
- **Parameter efficiency**: Uses hypernetworks to generate appropriate weights for each scale
- **Improved performance**: Achieves comparable or better PSNR scores than individual SRCNN models
- **Flexible architecture**: Can easily be extended to additional scale factors

## üß© Repository Structure

```
‚îú‚îÄ‚îÄ SRCNN/
‚îÇ   ‚îú‚îÄ‚îÄ SRCNN_utils.py           # Core utilities for the SRCNN model
‚îÇ   ‚îú‚îÄ‚îÄ SRCNN_train.py           # Training script for individual SRCNN models
‚îÇ   ‚îî‚îÄ‚îÄ SRCNN_train_multi_scaling.py  # Script to train multiple scale factors
‚îú‚îÄ‚îÄ HyperSRCNN/
‚îÇ   ‚îú‚îÄ‚îÄ HyperSRCNN_utils.py      # Core utilities for the HyperSRCNN model
‚îÇ   ‚îî‚îÄ‚îÄ HyperSRCNN_train.py      # Training script for the hypernetwork
‚îú‚îÄ‚îÄ inference_examples/          # Example images and inference results
‚îî‚îÄ‚îÄ models/                      # Pre-trained model weights
```

## üî¨ Models

### SRCNN
The Super-Resolution Convolutional Neural Network (SRCNN) is a classic deep learning approach to super-resolution. Our implementation follows the architecture from the original paper with three convolutional layers:
- 9√ó9 kernels with 64 feature maps (patch extraction and representation)
- 5√ó5 kernels with 32 feature maps (non-linear mapping)
- 5√ó5 kernels with 3 feature maps (reconstruction)

### HyperSRCNN
HyperSRCNN consists of two main components:
1. **Hypernetwork (HNet)**: Generates weights for the target network based on the scale factor
   - Takes a scale embedding (from scale factors 2√ó, 4√ó, 8√ó, 16√ó)
   - Contains fully connected layers to generate appropriate weights
2. **Target Network (MNet)**: SRCNN model that uses weights generated by HNet
   - Has the same architecture as standard SRCNN but no fixed weights
   - Adapts to different scale factors by using HNet-generated weights

## üöÄ Getting Started

### Prerequisites

```bash
# Clone the repository
git clone https://github.com/username/hypersrcnn.git
cd hypersrcnn

# Install dependencies
pip install torch torchvision tqdm numpy matplotlib pillow pandas
```

### Training

#### Training individual SRCNN models:

```bash
# Train a single SRCNN model for a specific scale factor
python SRCNN/SRCNN_train.py --scale_factor 2

# Train multiple SRCNN models for different scale factors
python SRCNN/SRCNN_train_multi_scaling.py
```

#### Training the HyperSRCNN model:

```bash
# Train the hypernetwork to handle multiple scale factors
python HyperSRCNN/HyperSRCNN_train.py
```

### Inference

To perform super-resolution on images using a trained model:

```python
from HyperSRCNN_utils import comprehensive_inference

# Path to the hypernetwork model
hyper_checkpoint_path = 'models/hypernetwork_checkpoint_best.pth'

# Dictionary mapping scale factors to SRCNN model paths (for comparison)
srcnn_model_paths = {
    2: 'models/srcnn_sf2_best.pth',
    4: 'models/srcnn_sf4_best.pth',
    8: 'models/srcnn_sf8_best.pth',
    16: 'models/srcnn_sf16_best.pth'
}

# Perform inference
results = comprehensive_inference(
    hyper_checkpoint_path=hyper_checkpoint_path,
    srcnn_model_paths=srcnn_model_paths,
    image_path='path/to/image.jpg',
    scale_factor_index=0,  # 0=2√ó, 1=4√ó, 2=8√ó, 3=16√ó
    output_dir='results'
)
```

To process multiple images:

```python
from HyperSRCNN_utils import batch_comprehensive_inference

batch_comprehensive_inference(
    hyper_checkpoint_path=hyper_checkpoint_path,
    srcnn_model_paths=srcnn_model_paths,
    image_dir='path/to/images',
    scale_factor_index=0,  # 0=2√ó, 1=4√ó, 2=8√ó, 3=16√ó
    output_dir='results'
)
```

## üìä Results

HyperSRCNN demonstrates competitive performance compared to individually trained SRCNN models:

| Scale Factor | Bicubic (PSNR) | SRCNN (PSNR) | HyperSRCNN (PSNR) |
|--------------|----------------|--------------|-------------------|
| 2√ó           | 28.32 dB       | 30.45 dB     | 30.38 dB          |
| 4√ó           | 25.18 dB       | 26.97 dB     | 27.04 dB          |
| 8√ó           | 22.63 dB       | 23.75 dB     | 23.81 dB          |
| 16√ó          | 20.14 dB       | 20.98 dB     | 21.05 dB          |

## üîç Related Work

This repository also includes implementations of other architectures for comparison:

- **DRCT (Dense Residual Contextual Transformer)**: A transformer-based model for super-resolution
- **RealDRCTGAN/RealDRCTMSE**: Models targeting real-world degradations with GAN or MSE losses

## üìö Citation

If you find this code useful for your research, please consider citing:

```
@article{hyperSRCNN2025,
  title={HyperSRCNN: A Hypernetwork Approach to Multi-Scale Super Resolution},
  author={Kurtenbach, David},
  journal={arXiv preprint},
  year={2025}
}
```

## üîì License

This project is licensed under the MIT License - see the LICENSE file for details.
